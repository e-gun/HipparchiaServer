# -*- coding: utf-8 -*-
"""
	HipparchiaServer: an interface to a database of Greek and Latin texts
	Copyright: E Gunderson 2016-17
	License: GNU GENERAL PUBLIC LICENSE 3
		(see LICENSE in the top level directory of the distribution)
"""
import re
from string import punctuation


def removegravity(accentedword):
	"""
	turn all graves into accutes so you can match the dictionary form
	:param accentedword:
	:return:
	"""
	# this failed to work when i typed the greekkeys versions: look out for identical looks with diff unicode vals...
	# meanwhile eta did not work until the unicode codes were forced...

	terminalgravea = re.compile(r'([á½°á½²á½¶á½¸á½ºá½´á½¼á¼‚á¼’á¼²á½‚á½’á¼¢á½¢á¾ƒá¾“á¾£á¾‚á¾’á¾¢])$')
	terminalgraveb = re.compile(r'([á½°á½²á½¶á½¸á½ºá½´á½¼á¼‚á¼’á¼²á½‚á½’á¼¢á½¢á¾ƒá¾“á¾£á¾‚á¾’á¾¢])(.)$')

	try:
		if accentedword[-1] in 'á½°á½²á½¶á½¸á½ºá½´á½¼á¼‚á¼’á¼²á½‚á½’á¼¢á½¢á¾ƒá¾“á¾£á¾‚á¾’á¾¢':
			accentedword = re.sub(terminalgravea, forceterminalacute, accentedword)
	except IndexError:
		# the word was not >0 char long
		pass
	try:
		if accentedword[-2] in 'á½°á½²á½¶á½¸á½ºá½´á½¼á¼‚á¼’á¼²á½‚á½’á¼¢á½¢á¾ƒá¾“á¾£á¾‚á¾’á¾¢':
			accentedword = re.sub(terminalgraveb, forceterminalacute, accentedword)
	except IndexError:
		# the word was not >1 char long
		pass

	return accentedword


def forceterminalacute(matchgroup):
	"""
	Î¸Î±Î¼Î¬ and Î¸Î±Î¼á½° need to be stored in the same place

	otherwise you will click on Î¸Î±Î¼á½°, search for Î¸Î±Î¼Î¬ and get prevalence data that is not what you really wanted

	:param match:
	:return:
	"""

	map = { 'á½°': 'Î¬',
	        'á½²': 'Î­',
	        'á½¶': 'Î¯',
	        'á½¸': 'ÏŒ',
	        'á½º': 'Ï',
	        'á½´': 'Î®',
	        'á½¼': 'ÏŽ',
			'á¼‚': 'á¼„',
			'á¼’': 'á¼”',
			'á¼²': 'á¼´',
			'á½‚': 'á½„',
			'á½’': 'á½”',
			'á¼¢': 'á¼¤',
			'á½¢': 'á½¤',
			'á¾ƒ': 'á¾…',
			'á¾“': 'á¾•',
			'á¾£': 'á¾¥',
			'á¾‚': 'á¾„',
			'á¾’': 'á¾”',
			'á¾¢': 'á¾¤',
		}

	substitute = map[matchgroup[1]]
	try:
		# the word did not end with a vowel
		substitute += matchgroup[2]
	except:
		# the word ended with a vowel
		pass

	return substitute


def stripaccents(texttostrip, transtable=None):
	"""

	turn á¾¶ into Î±, etc

	there are more others ways to do this; but this is the fast way
	it turns out that this was one of the slowest functions in the profiler

	transtable should be passed here outside of a loop
	but if you are just doing things one-off, then it is fine to have
	stripaccents() look up transtable itself

	:param texttostrip:
	:return:
	"""

	if transtable == None:
		transtable = buildhipparchiatranstable()

	stripped = texttostrip.translate(transtable)

	return stripped


def buildhipparchiatranstable():
	"""

	pulled this out of stripaccents() so you do not maketrans 200k times when
	polytonicsort() sifts an index

	:return:
	"""

	invals = ['á¼€á¼á¼‚á¼ƒá¼„á¼…á¼†á¼‡á¾€á¾á¾‚á¾ƒá¾„á¾…á¾†á¾‡á¾²á¾³á¾´á¾¶á¾·á¾°á¾±á½°Î¬á¼á¼‘á¼’á¼“á¼”á¼•á½²Î­á¼°á¼±á¼²á¼³á¼´á¼µá¼¶á¼·á½¶Î¯á¿á¿‘á¿’Îá¿–á¿—Îá½€á½á½‚á½ƒá½„á½…ÏŒá½¸á½á½‘á½’á½“á½”á½•á½–á½—Ï‹á¿ á¿¡á¿¢Î°á¿¦á¿§Ïá½ºá¾á¾‘á¾’á¾“á¾”á¾•á¾–á¾—á¿‚á¿ƒá¿„á¿†á¿‡á¼¤á¼¢á¼¥á¼£á½´Î®á¼ á¼¡á¼¦á¼§á½ á½¡á½¢á½£á½¤á½¥á½¦á½§á¾ á¾¡á¾¢á¾£á¾¤á¾¥á¾¦á¾§á¿²á¿³á¿´á¿¶á¿·ÏŽá½¼']
	outvals = ['Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±ÎµÎµÎµÎµÎµÎµÎµÎµÎ¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¿Î¿Î¿Î¿Î¿Î¿Î¿Î¿Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Ï…Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰']

	invals.append('á¾ˆá¾‰á¾Šá¾‹á¾Œá¾á¾Žá¾á¼ˆá¼‰á¼Šá¼‹á¼Œá¼á¼Žá¼Î‘á¼˜á¼™á¼šá¼›á¼œá¼Î•á¼¸á¼¹á¼ºá¼»á¼¼á¼½á¼¾á¼¿Î™á½ˆá½‰á½Šá½‹á½Œá½ÎŸá½™á½›á½á½ŸÎ¥á¾˜á¾™á¾šá¾›á¾œá¾á¾žá¾Ÿá¼¨á¼©á¼ªá¼«á¼¬á¼­á¼®á¼¯Î—á¾¨á¾©á¾ªá¾«á¾¬á¾­á¾®á¾¯á½¨á½©á½ªá½«á½¬á½­á½®á½¯Î©á¿¤á¿¥á¿¬Î’Î¨Î”Î¦Î“ÎžÎšÎ›ÎœÎÎ Ï˜Î¡ÏƒÎ£Ï‚Ï¹Î¤Î§Î˜Î–')
	outvals.append('Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±Î±ÎµÎµÎµÎµÎµÎµÎµÎ¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¹Î¿Î¿Î¿Î¿Î¿Î¿Î¿Ï…Ï…Ï…Ï…Ï…Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Î·Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰Ï‰ÏÏÏÎ²ÏˆÎ´Ï†Î³Î¾ÎºÎ»Î¼Î½Ï€Ï™ÏÏ²Ï²Ï²Ï²Ï„Ï‡Î¸Î¶')

	invals.append('vUjÃÃ„Ã¡Ã¤Ã‰Ã‹Ã©Ã«ÃÃÃ­Ã¯Ã“Ã–Ã³Ã¶ÃœÃšÃ¼Ãº')
	outvals.append('uViaaaaeeeeiiiioooouuuu')

	invals = ''.join(invals)
	outvals = ''.join(outvals)

	transtable = str.maketrans(invals, outvals)

	return transtable


def gkattemptelision(hypenatedgreekheadword):
	"""

	useful debug query:
		select * from greek_lemmata where dictionary_entry like '%á¼€Ï€ÏŒ-%'

	a difficult class of entry: multiple prefixes
		á½‘Ï€ÏŒ,ÎºÎ±Ï„Î¬-ÎºÎ»á¿„Î¶Ï‰1
		á½‘Ï€ÏŒ,ÎºÎ±Ï„Î¬,á¼Îº-Î»Î¬Ï‰1
		á½‘Ï€ÏŒ,á¼Î½-Î´ÏÏ‰1
		á½‘Ï€ÏŒ,á¼Îº-Î»Î¬Ï‰1
		á½‘Ï€ÏŒ,á¼Îº-Îµá¼´ÏÏ‰2
		á½‘Ï€ÏŒ,á¼Îº-á¼ÏÎ¬Ï‰1
		á½‘Ï€ÏŒ,á¼Îº-Î´ÏÏ‰1
		á½‘Ï€ÏŒ,á¼Îº-á¼€ÏÎ¬Ï‰2
		á½‘Ï€ÏŒ,á¼€Î½Î¬,á¼€Ï€ÏŒ-Î½Î­Ï‰1
		á½‘Ï€ÏŒ,á¼€Î½Î¬,á¼€Ï€ÏŒ-Î±á½”Ï‰2

	this will try to do it all at a go, but ideally a MorphPossibilityObject.getbaseform() call will
	send nothing worse than things that look like 'á½‘Ï€ÏŒ,á¼Îº-Î´ÏÏ‰' here since that function attempts to
	call this successively in the case of multiple compounds: first you get á¼€Ï€ÏŒ-Î±á½”Ï‰2 then you ask for
	á¼€Î½Î¬-á¼€Ï€Î±á½”Ï‰2, then you ask for á½‘Ï€ÏŒ-á¼€Î½Î¬Ï€ÏŒÎ±á½”Ï‰2

	IN PROGRESS BUT MOSTLY WORKING FOR GREEK

	Latin works on all of the easy cases; no effort made on the hard ones yet

	:param hypenatedgreekheadword:
	:return:
	"""

	entry = hypenatedgreekheadword
	terminalacute = re.compile(r'[Î¬Î­Î¯ÏŒÏÎ®ÏŽ]')
	initialrough = re.compile(r'[á¼á¼‘á¼±á½á½‘á¼¡á½¡á¿¥á¼ƒá¼“á¼³á½ƒá½“á¼£á½£]')
	initialsmooth = re.compile(r'[á¼€á¼á¼°á½€á½á¼ á½ á¼„á¼”á¼´á½„á½”á¼¤á½¤]')

	unaspirated = 'Ï€'
	aspirated = 'Ï†'

	units = hypenatedgreekheadword.split(',')
	hyphenated = units[-1]

	prefix = hyphenated.split('-')[0]
	stem = hyphenated.split('-')[1]

	if re.search(terminalacute, prefix[-1]) and re.search(initialrough, stem[0]) is None and re.search(initialsmooth, stem[0]):
		# print('A')
		# vowel + vowel: 'á¼€Ï€ÏŒ-á¼€Î¸ÏÎ­Ï‰'
		entry = prefix[:-1]+stripaccents(stem[0])+stem[1:]
	elif re.search(terminalacute, prefix[-1]) and re.search(initialrough, stem[0]) is None and re.search(initialrough, stem[0]) is None:
		# print('B')
		# vowel + consonant: 'á¼€Ï€ÏŒ-Î½Î­Ï‰'
		entry = prefix[:-1]+stripaccents(prefix[-1])+stem
	elif re.search(terminalacute, prefix[-1]) is None and re.search(initialrough, stem[0]) is None and re.search(initialrough, stem[0]) is None:
		# consonant + consonant: 'á¼Îº-Î´Î±Ï²ÏÎ½Ï‰'
		if prefix[-1] not in ['Î½'] and stem[0] not in ['Î³', 'Î»', 'Î¼']:
			# print('C1')
			# consonant + consonant: 'á¼Îº-Î´Î±Ï²ÏÎ½Ï‰'
			entry = prefix+stem
		elif prefix[-1] in ['Î½'] and stem[0] in ['Î³', 'Î»', 'Î¼', 'Ï²']:
			# print('C2')
			# consonant + consonant: 'Ï²ÏÎ½-Î¼Î½Î·Î¼Î¿Î½ÎµÏÏ‰'
			if prefix == 'Ï²ÏÎ½':
				prefix = stripaccents(prefix)
			entry = prefix[:-1]+stem[0]+stem
		elif prefix[-1] in ['Î½']:
			#print('C3')
			prefix = stripaccents(prefix)
			entry = prefix+stem
		else:
			#print('C0')
			pass
	elif re.search(terminalacute, prefix[-1]) and re.search(initialrough, stem[0]) and re.search(unaspirated, prefix[-2]):
		# print('D')
		# vowel + rough and 'Ï€' is in the prefix
		entry = prefix[:-2] + aspirated + stripaccents(stem[0]) + stem[1:]


	return entry


def latattemptelision(hypenatedlatinheadword):
	"""

	useful debug query:
		ï»¿select * from latin_lemmata where dictionary_entry like '%-%'
		ï»¿select * from latin_lemmata where dictionary_entry like '%-%Â¹'

		de_-seroÂ¹
		con-manducoÂ¹
		per-misceo
		per-misceo
		prae-verto
		dis-sido

	typical cases:
		just combine
		drop one
		merge consonants

	in progress: a fair number of cases are still unhandled

	:param hypenatedgreekheadword:
	:return:
	"""

	hypenatedlatinheadword = re.sub(r'_','',hypenatedlatinheadword)

	triplets = {
		'dsc': 'sc',
		'dse': 'sse',
		'dsi': 'ssi',
		'dso': 'sso',
		'dst': 'st',
		'dsu': 'ssu'
	}

	combinations = {
		'bd': 'd',
		'bf': 'ff',
		'bp': 'pp',
		'bm': 'mm',
		'br': 'rr',
		'dt': 'tt',
		'ds': 'ss',
		'nr': 'rr',
		'np': 'mp',
		'nm': 'mm',
		'dl': 'll',
		'dc': 'cc',
		'xr': 'r',
		'xn': 'n',
		'xm': 'm',
		'xv': 'v',
		'xl': 'l',
		'xd': 'd',
		'sn': 'n',
		'sm': 'm',
		'sr': 'r',
		'sf': 'ff',
		'xe': 'xse'
	}

	units = hypenatedlatinheadword.split(',')
	hyphenated = units[-1]

	prefix = hyphenated.split('-')[0]
	stem = hyphenated.split('-')[1]

	tail = prefix[-1]
	try:
		head = stem[0:1]
	except IndexError:
		head = stem[0]

	combination = tail+head

	if combination in triplets:
		entry = prefix[:-1]+triplets[combination]+stem[2:]
		return entry

	if combination in combinations:
		entry = prefix[:-1]+combinations[combination]+stem[1:]
		return entry

	entry = prefix + stem

	return entry


def tidyupterm(word, punct=None):
	"""
	remove gunk that should not be present in a cleaned line

	:param word:
	:return:
	"""

	if not punct:
		extrapunct = '\â€²â€µâ€™â€˜Â·Ì†Ìâ€œâ€â€žâ€”â€ âŒˆâŒ‹âŒŠâŸ«âŸªâµâ´âŸ§âŸ¦(Â«Â»â€ºâ€¹â¸â€žâ¸â¸Žâ¸‘â€“â‘â€“â’â“â”â•â–âŒâˆ™Ã—âšââ€–â¸“'
		punct = re.compile('[{s}]'.format(s=re.escape(punctuation + extrapunct)))

	# hard to know whether or not to do the editorial insertions stuff: âŸ«âŸªâŒˆâŒ‹âŒŠ
	# word = re.sub(r'\[.*?\]','', word) # '[o]missa' should be 'missa'
	word = re.sub(r'[0-9]', '', word)
	word = re.sub(punct, '', word)
	# best do punct before this next one...
	try:
		if re.search(r'[a-zA-z]', word[0]) is None:
			word = re.sub(r'[a-zA-z]', '', word)
	except:
		# must have been ''
		pass

	invals = u'jv'
	outvals = u'iu'
	word = word.translate(str.maketrans(invals, outvals))

	return word


def cleanaccentsandvj(texttostrip):
	"""
	turn á¾¶ into Î±, etc

	:return:
	"""

	substitutes = (
		('v', 'u'),
		('U', 'V'),
		('[Jj]', 'i'),
		('[ÃÃ„]', 'A'),
		('[Ã¡Ã¤]', 'a'),
		('[Ã‰Ã‹]', 'E'),
		('[Ã©Ã«]', 'e'),
		('[ÃÃ]', 'I'),
		('[Ã­Ã¯]', 'i'),
		('[Ã“Ã–]', 'O'),
		('[Ã³Ã¶]', 'o'),
		('[á¿¥á¿¤á¿¬]', 'Ï'),
		('[á¼€á¼á¼‚á¼ƒá¼„á¼…á¼†á¼‡á¾€á¾á¾‚á¾ƒá¾„á¾…á¾†á¾‡á¾²á¾³á¾´á¾¶á¾·á¾°á¾±á½°Î¬]', 'Î±'),
		('[á¼á¼‘á¼’á¼“á¼”á¼•á½²Î­]', 'Îµ'),
		('[á¼°á¼±á¼²á¼³á¼´á¼µá¼¶á¼·á½¶Î¯á¿á¿‘á¿’Îá¿–á¿—ÎÏŠ]', 'Î¹'),
		('[á½€á½á½‚á½ƒá½„á½…ÏŒá½¸]', 'Î¿'),
		('[á½á½‘á½’á½“á½”á½•á½–á½—Ï‹á¿ á¿¡á¿¢Î°á¿¦á¿§Ïá½º]', 'Ï…'),
		('[á½ á½¡á½¢á½£á½¤á½¥á½¦á½§á¾ á¾¡á¾¢á¾£á¾¤á¾¥á¾¦á¾§á¿²á¿³á¿´á¿¶á¿·ÏŽá½¼]', 'Ï‰'),
		('[á¾á¾‘á¾’á¾“á¾”á¾•á¾–á¾—á¿‚á¿ƒá¿„á¿†á¿‡á¼¤á¼¢á¼¥á¼£á½´Î®á¼ á¼¡á¼¦á¼§]', 'Î·'),
		('[á¾¨á¾©á¾ªá¾«á¾¬á¾­á¾®á¾¯á½¨á½©á½ªá½«á½¬á½­á½®á½¯Î©]', 'Ï‰'),
		('[á½ˆá½‰á½Šá½‹á½Œá½ÎŸ]', 'Î¿'),
		('[á¾ˆá¾‰á¾Šá¾‹á¾Œá¾á¾Žá¾á¼ˆá¼‰á¼Šá¼‹á¼Œá¼á¼Žá¼Î‘]', 'Î±'),
		('[á¼˜á¼™á¼šá¼›á¼œá¼Î•]', 'Îµ'),
		('[á¼¸á¼¹á¼ºá¼»á¼¼á¼½á¼¾á¼¿Î™Îª]', 'Î¹'),
		('[á½™á½›á½á½ŸÎ¥Î«]', 'Ï…'),
		('[á¾˜á¾™á¾šá¾›á¾œá¾á¾žá¾Ÿá¼¨á¼©á¼ªá¼«á¼¬á¼­á¼®á¼¯Î—]', 'Î·'),
		('Î’', 'Î²'),
		('Î¨', 'Ïˆ'),
		('Î”', 'Î´'),
		('Î¦', 'Ï†'),
		('Î“', 'Î³'),
		('Îž', 'Î¾'),
		('Îš', 'Îº'),
		('Î›', 'Î»'),
		('Îœ', 'Î¼'),
		('Î', 'Î½'),
		('Î ', 'Ï€'),
		('Ï˜', 'Ï™'),
		('Î¡', 'Ï'),
		('Ï¹', 'Ï²'),
		('Î¤', 'Ï„'),
		('Î˜', 'Î¸'),
		('Î–', 'Î¶')
	)

	for swap in range(0, len(substitutes)):
		texttostrip = re.sub(substitutes[swap][0], substitutes[swap][1], texttostrip)

	return texttostrip


def universalregexequivalent(searchterm):
	"""

	in order to properly highlight a polytonic word that you found via a unaccented search you need to convert:
		Ï€Î¿Ï„Î±Î¼Î¿Î½
	into:
		([Ï€Î ][Î¿á½€á½á½‚á½ƒá½„á½…ÏŒá½¸ÎŸá½ˆá½‰á½Šá½‹á½Œá½][Ï„Î¤][Î±á¼€á¼á¼‚á¼ƒá¼„á¼…á¼†á¼‡á¾€á¾á¾‚á¾ƒá¾„á¾…á¾†á¾‡á¾²á¾³á¾´á¾¶á¾·á¾°á¾±á½°Î¬á¾ˆá¾‰á¾Šá¾‹á¾Œá¾á¾Žá¾á¼ˆá¼‰á¼Šá¼‹á¼Œá¼á¼Žá¼Î‘][Î¼Îœ][Î¿á½€á½á½‚á½ƒá½„á½…ÏŒá½¸ÎŸá½ˆá½‰á½Šá½‹á½Œá½][Î½Î])

	NB: this function also takes care of capitalization issues: the search is always lower case, but results will be marked
	without regard to their case: 'Antonius', 'Kalendas', etc.

	this function is also called by searchdictionary() to address the Ï„Î®Î¸Î· vs Ï„Î·Î¸Î® issue

	:param searchterm:
	:return:
	"""

	# need to avoid having '\s' turn into '\[Ss]', etc.
	searchterm = re.sub(r'\\s', 'ðŸ˜€', searchterm)
	searchterm = re.sub(r'\\w', 'ðŸ‘½', searchterm)

	equivalents = {
		'Î±': '[Î±á¼€á¼á¼‚á¼ƒá¼„á¼…á¼†á¼‡á¾€á¾á¾‚á¾ƒá¾„á¾…á¾†á¾‡á¾²á¾³á¾´á¾¶á¾·á¾°á¾±á½°Î¬á¾ˆá¾‰á¾Šá¾‹á¾Œá¾á¾Žá¾á¼ˆá¼‰á¼Šá¼‹á¼Œá¼á¼Žá¼Î‘]',
		'Î²': '[Î²Î’]',
		'Ïˆ': '[ÏˆÎ¨]',
		'Î´': '[Î´Î”]',
		'Îµ': '[Îµá¼á¼‘á¼’á¼“á¼”á¼•á½²Î­Î•á¼˜á¼™á¼šá¼›á¼œá¼]',
		'Ï†': '[Ï†Î¦]',
		'Î³': '[Î³Î“]',
		'Î·': '[Î·á¾á¾‘á¾’á¾“á¾”á¾•á¾–á¾—á¿‚á¿ƒá¿„á¿†á¿‡á¼¤á¼¢á¼¥á¼£á½´Î®á¼¡á¼¦Î—á¾˜á¾™á¾šá¾›á¾œá¾á¾žá¾Ÿá¼¨á¼©á¼ªá¼«á¼¬á¼­á¼®á¼¯]',
		'Î¹': '[Î¹á¼°á¼±á¼²á¼³á¼´á¼µá¼¶á¼·á½¶Î¯á¿á¿‘á¿’Îá¿–á¿—Îá¼¸á¼¹á¼ºá¼»á¼¼á¼½á¼¾á¼¿Î™]',
		'Î¾': '[Î¾Îž]',
		'Îº': '[ÎºÎš]',
		'Î»': '[Î»Î›]',
		'Î¼': '[Î¼Îœ]',
		'Î½': '[Î½Î]',
		'Î¿': '[Î¿á½€á½á½‚á½ƒá½„á½…ÏŒá½¸ÎŸá½ˆá½‰á½Šá½‹á½Œá½]',
		'Ï€': '[Ï€Î ]',
		'Ï': '[ÏÎ¡á¿¥á¿¬]',
		'Ï²': '[ÏƒÏ‚Î£Ï²Ï¹]',
		'Ïƒ': '[ÏƒÏ‚Î£Ï²Ï¹]',
		'Ï‚': '[ÏƒÏ‚Î£Ï²Ï¹]',
		'Ï„': '[Ï„Î¤]',
		'Ï…': '[Ï…á½á½‘á½’á½“á½”á½•á½–á½—Ï‹á¿ á¿¡á¿¢Î°á¿¦á¿§Ïá½ºá½™á½›á½á½ŸÎ¥]',
		'Ï‰': '[Ï‰á½ á½¡á½¢á½£á½¤á½¥á½¦á½§á¾ á¾¡á¾¢á¾£á¾¤á¾¥á¾¦á¾§á¿²á¿³á¿´á¿¶á¿·ÏŽá½¼Î©á¾¨á¾©á¾ªá¾«á¾¬á¾­á¾®á¾¯á½¨á½©á½ªá½«á½¬á½­á½®á½¯Î©]',
		'Ï‡': '[Ï‡Î§]',
		'Î¸': '[Î¸Î˜]',
		'Î¶': '[Î¶Î–]',
		'b': '[Bb]',
		'c': '[Cc]',
		'd': '[Dd]',
		'f': '[Ff]',
		'g': '[Gg]',
		'h': '[Hh]',
		'j': '[JjIi]',
		'k': '[Kk]',
		'l': '[Ll]',
		'm': '[Mm]',
		'n': '[Nn]',
		'p': '[Pp]',
		'q': '[Qq]',
		'r': '[Rr]',
		's': '[Ss]',
		't': '[Tt]',
		'w': '[Ww]',
		'x': '[Xx]',
		'y': '[Yy]',
		'z': '[Zz]',
		'a': '[AaÃ¡Ã¤]',
		'e': '[EeÃ©Ã«]',
		'i': '[IiÃ­Ã¯Jj]',
		'o': '[OoÃ³Ã¶]',
		'u': '[UuÃ¼Vv]',
		'v': '[VvUuÃ¼]'
	}

	searchtermequivalent = ''
	searchterm = re.sub(r'(^\s|\s$)', '', searchterm)
	for c in searchterm:
		try:
			c = equivalents[c]
		except KeyError:
			pass
		searchtermequivalent += c
	# searchtermequivalent = '(^|)('+searchtermequivalent+')($|)'
	searchtermequivalent = re.sub(r'ðŸ˜€', '\s', searchtermequivalent)
	searchtermequivalent = re.sub(r'ðŸ‘½', '\w', searchtermequivalent)
	searchtermequivalent = '({s})'.format(s=searchtermequivalent)

	try:
		searchtermequivalent = searchtermequivalent
	except:
		# if you try something like '(Xá¼°' you will produce an error:
		# sre_constants.error: missing ), unterminated subpattern at position 0
		searchtermequivalent = None

	return searchtermequivalent


def depunct(stringtoclean, allowedpunctuationsting=None):
	"""

	'abc*d$ef, ghi;' + ',;' ==> 'abcdef, ghi;'

	:param wordtoclean:
	:param allowedpunctuationsting:
	:return:
	"""

	badpunct = punctuation
	if allowedpunctuationsting:
		badpunct = re.sub(r'[{ap}]'.format(ap=allowedpunctuationsting), '', badpunct)
	badpunct = r'[{np}]'.format(np=re.escape(badpunct))

	cleaned = re.sub(badpunct, '', stringtoclean)

	return cleaned