[A] latattemptelision() could use more love

MorphPossibilityObject.getlatinbaseform() needs work per-misceo
MorphPossibilityObject.getlatinbaseform() needs work permixtā, per-misceo
MorphPossibilityObject.getlatinbaseform() needs work praevortēmur, prae-verto
MorphPossibilityObject.getlatinbaseform() needs work dissīderent, dis-sido

[B] similarly
MorphPossibilityObject.getbaseform() is confused ἐνέρριπτεν, ἐν, ἐν-ῥίπτω ['ἐνέρριπτεν', 'ἐν', 'ἐν-ῥίπτω']
MorphPossibilityObject.getbaseform() is confused ἐνέρριψεν, ἐν, ἐν-ῥίπτω ['ἐνέρριψεν', 'ἐν', 'ἐν-ῥίπτω']
MorphPossibilityObject.getbaseform() is confused ἐνέρριψαν, ἐν, ἐν-ῥίπτω ['ἐνέρριψαν', 'ἐν', 'ἐν-ῥίπτω']
MorphPossibilityObject.getbaseform() is confused ἐνέρριψε, ἐν, ἐν-ῥίπτω ['ἐνέρριψε', 'ἐν', 'ἐν-ῥίπτω']

[C] resetsession

resetsession will reload '/' without clearing date range from html (but the range has been reset)
a second click will clear the display
js async timing issue, it seems
irritating to avoid "return redirect(url_for('frontpage'))" which is so simple and easy to call

[D] platform specific bug: FreeBSD %complete poll info not working with proximity search


[E] platform specific bug? Ryzen vs FreeBSD vs threads (vs C-states?)

[gone as of FreeBSD 11.2-RELEASE?]
[FreeBSD 12-ALPHA has a cousin: *regular* failure to execute the first search properly after launch]
[FreeBSD 12-ALPHA will hang if you poke at it long enough]
[SEARCHLISTCONNECTIONTYPE = 'redis' seems to fix this...]
[SEARCHLISTCONNECTIONTYPE = 'queue' seems to have more or less the same problem; perhaps less bad...]

workonsimplesearch() (and probably its kin)

a very odd bug in here on a Ryzen 1600x running FreeBSD 11.1: you can search for "mentior" 10x and
somewhere in those trials the search will fail: one of the threads will get stuck in this function
this cannot be reproduced on macOS 10.13.2 with identical versions of python and postgres installed...
this bug is not in Hipparchia? presumably it also does not affect just this function

you will not trigger the bug with the following number of workers set in config.py
    1
    2
    3
    4
at 5 and 6 you get fails: often right away
but then you can do more searches that will work for a while
then you will fail
then you can do more searches on top of this
this will leave you with two zombie threads and two eternally updating polls

PooledCoonections can give some insight into the failure:

success: lots of connections return
    connection returned to pool: cdxuheaxllwh
    connection returned to pool: lntxrxfazsae
    connection returned to pool: ycxhhbbfddjb
    connection returned to pool: plzhaoxekeif
    connection returned to pool: fqdeflurdxda
    connection returned to pool: pouehdobwalh
    connection returned to pool: qtuwhufcywwq
    connection returned to pool: zhqqklbrpcly
    connection returned to pool: ngtlbdtntppq
    connection returned to pool: gtilspjppzdt
    connection returned to pool: mkmentgxkmqc
    connection returned to pool: nnijmjgqylgs
    connection returned to pool: minqxopiocju
    connection returned to pool: sphojeucdudr
    connection returned to pool: eisdjqpreipq
    connection returned to pool: hhjryxvpohsi
    [22/Mar/2018 08:28:05] "GET /executesearch/1521721684476?skg=%CE%A8%CE%B7%CF%86%CE%B9%CF%B2%CE%B1%CE%BC%CE%AD%CE%BD%CE%B7%CF%B2%20%CE%B4%E1%BD%B2%20%CF%84%E1%BF%86%CF%B2%20%CE%B2%CE%BF%CF%85%CE%BB%E1%BF%86%CF%B2 HTTP/1.1" 200 -

freeze: 8 connections return; there are 10 workers...
    connection returned to pool: bomicybcsucs
    connection returned to pool: oonokovlecod
    connection returned to pool: jzeoyhukohml
    connection returned to pool: mlngnennlyif
    connection returned to pool: zkwxcabpeucx
    connection returned to pool: urcwtmarsxns
    connection returned to pool: ufowvlsfrcer
    connection returned to pool: qlscphoqoqpc

the choke seems more likely when you get many results really fast: some sort of problem with the lock on the managed list?

Could move back to Pool from Manager in searchdispatching in order to work some more on the hang problem
    NB: the old problem with Pool is the clumping of long dbs that means some workers have more
    work to do than others: address it by sorting placestosearch by # of words in the table.
    then you can call siftintopiles(). The downside is that you would always search a certain
    kind of work first (i.e, Byzantine commentaries).

*serious* refactoring obstacles:

    the searchobject vs the pool:
       RuntimeError: Synchronized objects should only be shared between processes through inheritance
    the connectionobject vs the pool:
       TypeError: can't pickle psycopg2.extensions.connection objects



[F] In progress: launches, but will not serve [NOT A PRIORITY FEATURE]

./bin/pip3 install pyopenssl

>>> from werkzeug.serving import make_ssl_devcert
>>> make_ssl_devcert('./HipparchiaServer/server/settings/hipparchia_openssl_key', host='localhost')
('./HipparchiaServer/server/settings/hipparchia_openssl_key.crt', './HipparchiaServer/server/settings/hipparchia_openssl_key.key')

run.py:

	from sys import argv
	from os import path
	basepath = path.dirname(argv[0])
	print('basepath', basepath)
	crt = '/server/settings/hipparchia_openssl_key.crt'
	key = '/server/settings/hipparchia_openssl_key.key'

	hipparchia.run(threaded=True, debug=False, host=hipparchia.config['LISTENINGADDRESS'], port=hipparchia.config['FLASKSERVEDFROMPORT'],
	               ssl_context=(basepath + crt, basepath + key))



[G] [not actually a case where we need debugging ATM] REDIS debug notes:

[build a connection by hand]

    import redis
    sock='/tmp/redis.sock'
    dbid=0
    poolsize=4
    port = 6379
    redisconnection = redis.ConnectionPool(host='localhost', port=port, db=dbid, max_connections=poolsize)
    # redisconnection = redis.ConnectionPool(connection_class=redis.UnixDomainSocketConnection, path=sock, db=dbid, max_connections=poolsize)
    c = redis.Redis(connection_pool=redisconnection)

ex queries:

    c.keys()
    len([k for k in c.keys() if b'_searchlist' in k])
    c.delete(b'dab1038f_searchlist')

    r = [k for k in c.keys() if b'remain' in k]
    a = [c.delete(key) for key in r]