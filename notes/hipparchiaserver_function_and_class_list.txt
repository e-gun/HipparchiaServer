hipparchia_venv/ $ cloc --not-match-f='^j' HipparchiaServer/
     169 text files.
     168 unique files.
      23 files ignored.

github.com/AlDanial/cloc v 1.82  T=0.65 s (233.7 files/s, 58681.8 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Python                         112           6073           8568          14888
CSS                              3            616            141           2490
HTML                            27            177             26           1811
XML                              5              0              0           1475
JavaScript                       5            265            161           1455
Markdown                         1             62              0            217
-------------------------------------------------------------------------------
SUM:                           153           7193           8896          22336
-------------------------------------------------------------------------------

server/ $  grep "^class" */*.py && grep "^def " *.py && grep "^def " */*.py
dbsupport/redisdbfunctions.py:class NullRedis(object):
dbsupport/redisdbfunctions.py:class PooledRedisBorg(object):
hipparchiaobjects/browserobjects.py:class BrowserOutputObject(object):
hipparchiaobjects/browserobjects.py:class BrowserPassageObject(object):
hipparchiaobjects/connectionobject.py:class GenericConnectionObject(object):
hipparchiaobjects/connectionobject.py:class PooledConnectionObject(GenericConnectionObject):
hipparchiaobjects/connectionobject.py:class SimpleConnectionObject(GenericConnectionObject):
hipparchiaobjects/cssformattingobject.py:class CssFormattingObject(object):
hipparchiaobjects/dbtextobjects.py:class dbAuthor(object):
hipparchiaobjects/dbtextobjects.py:class dbOpus(object):
hipparchiaobjects/dbtextobjects.py:class dbMorphologyObject(object):
hipparchiaobjects/helperobjects.py:class LowandHighInfo(object):
hipparchiaobjects/helperobjects.py:class MPCounter(object):
hipparchiaobjects/helperobjects.py:class QueryCombinator(object):
hipparchiaobjects/helperobjects.py:class LSIVectorCorpus(object):
hipparchiaobjects/helperobjects.py:class LogEntropyVectorCorpus(object):
hipparchiaobjects/lexicalobjects.py:class dbDictionaryEntry(object):
hipparchiaobjects/lexicalobjects.py:class dbGreekWord(dbDictionaryEntry):
hipparchiaobjects/lexicalobjects.py:class dbLatinWord(dbDictionaryEntry):
hipparchiaobjects/lexicaloutputobjects.py:class multipleWordOutputObject(object):
hipparchiaobjects/lexicaloutputobjects.py:class lexicalOutputObject(object):
hipparchiaobjects/morphanalysisobjects.py:class MorphAnalysis(object):
hipparchiaobjects/morphanalysisobjects.py:class BaseFormMorphology(object):
hipparchiaobjects/morphanalysisobjects.py:class ConjugatedFormAnalysis(object):
hipparchiaobjects/morphanalysisobjects.py:class DeclinedFormAnalysis(object):
hipparchiaobjects/morphanalysisobjects.py:class AdvAnalysis(object):
hipparchiaobjects/morphanalysisobjects.py:class IndeclAnalysis(object):
hipparchiaobjects/morphanalysisobjects.py:class PrinciplePartFunctions(object):
hipparchiaobjects/morphanalysisobjects.py:class DeclinedFormFunctions(object):
hipparchiaobjects/morphanalysisobjects.py:class ConjugatedFormFunctions(object):
hipparchiaobjects/morphologyobjects.py:class MorphPossibilityObject(object):
hipparchiaobjects/morphologyobjects.py:class dbLemmaObject(object):
hipparchiaobjects/progresspoll.py:class SharedMemoryProgressPoll(object):
hipparchiaobjects/progresspoll.py:class RedisProgressPoll(object):
hipparchiaobjects/searchfunctionobjects.py:class GenericSearchFunctionObject(object):
hipparchiaobjects/searchfunctionobjects.py:class RedisSearchFunctionObject(GenericSearchFunctionObject):
hipparchiaobjects/searchfunctionobjects.py:class ManagedListSearchFunctionObject(GenericSearchFunctionObject):
hipparchiaobjects/searchfunctionobjects.py:class QueuedSearchFunctionObject(GenericSearchFunctionObject):
hipparchiaobjects/searchobjects.py:class SearchObject(object):
hipparchiaobjects/searchobjects.py:class SearchOutputObject(object):
hipparchiaobjects/searchobjects.py:class SearchResult(object):
hipparchiaobjects/vectorobjects.py:class VectorValues(object):
hipparchiaobjects/wordcountobjects.py:class dbWordCountObject(object):
hipparchiaobjects/wordcountobjects.py:class dbHeadwordObject(dbWordCountObject):
hipparchiaobjects/worklineobject.py:class dbWorkLine(object):
calculatewordweights.py:def findtemporalweights(language: str) -> dict:
calculatewordweights.py:def findccorporaweights() -> dict:
calculatewordweights.py:def workobjectgeneraweights(language: str, iscollapsed: bool, workobjects) -> dict:
calculatewordweights.py:def findgeneraweights(language: str, collapsed=False) -> dict:
calculatewordweights.py:def findchronologicalweights(era: str, language: str) -> int:
calculatewordweights.py:def findgenreweightfromworkobject(genre: str, language: str, workdict: dict) -> int:
calculatewordweights.py:def findcorpusweight(corpus: str, language: str) -> int:
calculatewordweights.py:def findcorpusweightviawordcounts(corpus: str) -> int:
commandlineoptions.py:def getcommandlineargs():
configureatstartup.py:def startupprint(message: str):
browsing/browserfunctions.py:def buildbrowseroutputobject(authorobject: dbAuthor, workobject: dbOpus, locusindexvalue: int, dbcursor) -> BrowserOutputObject:
browsing/browserfunctions.py:def checkfordocumentmetadata(workline: dbWorkLine, workobject: dbOpus) -> str:
browsing/browserfunctions.py:def fetchhtmltemplateformetadatarow(shownotes=True):
browsing/browserfunctions.py:def findlinenumberfromcitation(method: str, citation: str, workobject: dbOpus, dbcursor) -> tuple:
browsing/browserfunctions.py:def findlinenumberfromlinenumber(citation: str, workobject: dbOpus, resultmessage: str, dbcursor) -> tuple:
browsing/browserfunctions.py:def findlinenumberfromlocus(citation: str, workobject: dbOpus, resultmessage: str, dbcursor) -> tuple:
browsing/browserfunctions.py:def findlinenumberfromperseus(citation: str, workobject: dbOpus, resultmessage: str, dbcursor) -> tuple:
dbsupport/bulkdboperations.py:def loadallauthorsasobjects() -> dict:
dbsupport/bulkdboperations.py:def loadallworksasobjects() -> dict:
dbsupport/bulkdboperations.py:def loadlemmataasobjects() -> dict:
dbsupport/bulkdboperations.py:def loadallworksintoallauthors(authorsdict, worksdict) -> dict:
dbsupport/citationfunctions.py:def findvalidlevelvalues(workobject: dbOpus, partialcitationtuple: tuple, cursor) -> LowandHighInfo:
dbsupport/citationfunctions.py:def locusintocitation(workobject: dbOpus, lineobject: dbWorkLine) -> str:
dbsupport/citationfunctions.py:def prolixlocus(workobject: dbOpus, citationtuple: tuple) -> str:
dbsupport/citationfunctions.py:def finddblinefromlocus(workobject: dbOpus, citationtuple: tuple, dbcursor) -> int:
dbsupport/citationfunctions.py:def finddblinefromincompletelocus(workobject: dbOpus, citationlist: list, cursor, trialnumber=0) -> dict:
dbsupport/citationfunctions.py:def perseuslookupleveltrimmer(workobject: dbOpus, citationlist: list, cursor, trialnumber: int) -> dict:
dbsupport/citationfunctions.py:def perseuslookupchangecase(citationlist: list) -> list:
dbsupport/citationfunctions.py:def perseusdelabeler(citationlist: list, workobject: dbOpus) -> list:
dbsupport/citationfunctions.py:def perseuscitationsintohipparchiacitations(citationlist: list) -> list:
dbsupport/dbbuildinfo.py:def buildoptionchecking() -> dict:
dbsupport/dbbuildinfo.py:def versionchecking(activedbs: list, expectedsqltemplateversion: str) -> str:
dbsupport/dblinefunctions.py:def dblineintolineobject(dbline: tuple) -> dbWorkLine:
dbsupport/dblinefunctions.py:def grabonelinefromwork(workdbname: str, lineindex: int, cursor) -> tuple:
dbsupport/dblinefunctions.py:def returnfirstlinenumber(workid: str, cursor) -> int:
dbsupport/dblinefunctions.py:def makeablankline(work: str, fakelinenumber: int) -> dbWorkLine:
dbsupport/dblinefunctions.py:def bulklinegrabber(table: str, column: str, criterion: str, setofcriteria, cursor) -> dict:
dbsupport/dblinefunctions.py:def grablistoflines(table: str, uidlist: list) -> list:
dbsupport/dblinefunctions.py:def grabbundlesoflines(worksandboundaries: dict, cursor) -> list:
dbsupport/dblinefunctions.py:def bulkenvironsfetcher(table: str, searchresultlist: list, context: int) -> list:
dbsupport/lexicaldbfunctions.py:def headwordsearch(seeking: str, limit: str, usedictionary: str, usecolumn: str) -> List[tuple]:
dbsupport/lexicaldbfunctions.py:def reversedictionarylookup(seeking: str, usedict: str, limit=None) -> List:
dbsupport/lexicaldbfunctions.py:def findentrybyid(usedict: str, entryid: str) -> dbDictionaryEntry:
dbsupport/lexicaldbfunctions.py:def querytotalwordcounts(word: str, dbcursor=None) -> dbHeadwordObject:
dbsupport/lexicaldbfunctions.py:def probedictionary(usedictionary: str, usecolumn: str, seeking: str, syntax: str, dbcursor=None, trialnumber=0) -> List:
dbsupport/lexicaldbfunctions.py:def convertdictionaryfindintowordobject(foundline: tuple, usedictionary: str, dbcursor):
dbsupport/lexicaldbfunctions.py:def findcountsviawordcountstable(wordtocheck):
dbsupport/lexicaldbfunctions.py:def grablemmataobjectfor(db, dbcursor=None, word=None, xref=None, allowsuperscripts=False):
dbsupport/lexicaldbfunctions.py:def findparserxref(wordobject) -> str:
dbsupport/lexicaldbfunctions.py:def lookformorphologymatches(word: str, dbcursor, trialnumber=0, revertword=None, rewrite=None, furtherdeabbreviate=False) -> dbMorphologyObject:
dbsupport/lexicaldbfunctions.py:def bulkfindwordcounts(listofwords: List[str]) -> List[dbWordCountObject]:
dbsupport/lexicaldbfunctions.py:def bulkfindmorphologyobjects(listofwords: List[str], language: str) -> List[dbMorphologyObject]:
dbsupport/miscdbfunctions.py:def resultiterator(cursor, chunksize=5000):
dbsupport/miscdbfunctions.py:def dbloadasingleworkobject(workuniversalid: str) -> dbOpus:
dbsupport/miscdbfunctions.py:def findselectionboundaries(workobject: dbOpus, selection: str, cursor) -> tuple:
dbsupport/miscdbfunctions.py:def simplecontextgrabber(authortable: str, focusline: int, linesofcontext: int, cursor) -> list:
dbsupport/miscdbfunctions.py:def perseusidmismatch(badworkdbnumber: str, cursor) -> str:
dbsupport/miscdbfunctions.py:def returnfirstwork(authorid: str, cursor) -> str:
dbsupport/miscdbfunctions.py:def makeanemptyauthor(universalid: str) -> dbAuthor:
dbsupport/miscdbfunctions.py:def makeanemptywork(universalid: str) -> dbOpus:
dbsupport/miscdbfunctions.py:def getpostgresserverversion() -> str:
dbsupport/miscdbfunctions.py:def probefordatabases() -> dict:
dbsupport/miscdbfunctions.py:def icanpickleconnections() -> bool:
dbsupport/miscdbfunctions.py:def buildauthorworkandpassage(author: str, work: str, passage: str, authordict: dict, workdict: dict, dbcursor) -> dict:
dbsupport/redisdbfunctions.py:def establishredisconnection() -> redis.client.Redis:
dbsupport/redisdbfunctions.py:def buildredissearchlist(listofsearchlocations: List, searchid: str):
dbsupport/redisdbfunctions.py:def loadredisresults(searchid):
dbsupport/tablefunctions.py:def assignuniquename(maxlength=None) -> str:
dbsupport/vectordbfunctions.py:def createvectorstable():
dbsupport/vectordbfunctions.py:def createstoredimagestable():
dbsupport/vectordbfunctions.py:def storevectorindatabase(searchobject: SearchObject, vectortype: str, vectorspace):
dbsupport/vectordbfunctions.py:def checkforstoredvector(searchobject: SearchObject, vectortype: str, careabout='thumbprint'):
dbsupport/vectordbfunctions.py:def fetchverctorenvirons(hitdict: dict, searchobject: SearchObject) -> list:
experimental/gensimexperiments.py:def gensimexperiment(so):
experimental/gensimexperiments.py:def doc2vecbuildspace(morphdict, sentences):
experimental/gensimexperiments.py:def logentropybuildspace(morphdict, sentences):
experimental/graphingexperiments.py:def bokehgraphmatches(graphtitle, searchterm, mostsimilartuples, terms, relevantconnections, vtype):
experimental/scikitlearnvectors.py:def fortestingpurposessklearnselectedworks(searchobject):
experimental/scikitlearnvectors.py:def generatesimilarsentenceoutput(corehtml, searchobject, workssearched, matches):
experimental/scikitlearnvectors.py:def sklearntextfeatureextractionandevaluation(sentences, searchobject):
experimental/scikitlearnvectors.py:def simplesktextcomparison(sentencetuples, searchobject, stopwordsbyheadword=False):
experimental/scikitlearnvectors.py:def print_top_words(model, feature_names, n_top_words):
experimental/scikitlearnvectors.py:def ldatopicmodeling(sentencetuples, searchobject):
experimental/tensorflowvectors.py:def tensorgraphelectedworks(searchobject):
experimental/tensorflowvectors.py:def tftrainondata(sentences, searchobject):
experimental/tensorflowvectors.py:def builddatasetdict(words, vocabularysize):
experimental/tensorflowvectors.py:def tfgeneratetrainingbatch(batchsize, numberofskips, skipwindow, thedata, dataindex):
experimental/tensorflowvectors.py:def tfplotwithlabels(low_dim_embs, labels, filename):
experimental/tensorflowvectors.py:def tfnlptraining(sentences, searchobject):
experimental/tensorflowvectors.py:def converttexttoinexvalues(sentences, morphdict):
experimental/tensorflowvectors.py:def generatetfbatch(sentences, batchsize, windowsize, method='cbow'):
experimental/tensorflowvectors.py:def tfnlpwork(textasvals, wordsmappedtocodes, codesmappedtowords, activepoll):
formatting/abbreviations.py:def deabbreviateauthors(authorabbr: str, lang: str) -> str:
formatting/abbreviations.py:def deabrevviategreekauthors() -> Dict[str, str]:
formatting/abbreviations.py:def deabrevviatelatinauthors() -> Dict[str, str]:
formatting/abbreviations.py:def unpackcommonabbreviations(potentialabbreviaiton: str, furtherunpack: bool) -> str:
formatting/betacodeescapes.py:def andsubstitutes(match: re.match) -> str:
formatting/betacodetounicode.py:def replacegreekbetacode(texttoclean: str) -> str:
formatting/betacodetounicode.py:def capitalletters(betacode: str) -> str:
formatting/betacodetounicode.py:def capitalsmoothgraveadscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalroughgraveadscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalsmoothacuteadscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalroughacuteadscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalsmoothcircumflexadscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalroughcircumflexadscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalsmoothgrave(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalroughgrave(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalsmoothacute(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalroughacute(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalsmoothcircumflex(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalroughcircumflex(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalsmooth(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalrough(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalgrave(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitalacute(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitaladscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def capitals(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseletters(betacode: str) -> str:
formatting/betacodetounicode.py:def lowercasesmoothgravesubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughgravesubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmoothacutesubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughacutesubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmoothcircumflexsubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughcircumflexsubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmoothgrave(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughgrave(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmoothacute(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughacute(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmoothcircumflex(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughcircumflex(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasegravesub(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseacutedsub(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesircumflexsub(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmoothsub(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseroughsub(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasegravediaresis(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseacutediaresis(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesircumflexdiaresis(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesmooth(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaserough(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasegrave(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercaseacute(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercascircumflex(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasediaresis(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercasesubscript(match: re.match, g=1) -> str:
formatting/betacodetounicode.py:def lowercases(match: re.match, g=0) -> str:
formatting/bibliographicformatting.py:def bcedating(s=session) -> tuple:
formatting/bibliographicformatting.py:def formatauthinfo(authorobject: dbAuthor) -> str:
formatting/bibliographicformatting.py:def woformatworkinfo(workobject: dbOpus) -> str:
formatting/bibliographicformatting.py:def formatname(workobject: dbOpus, authorobject: dbAuthor) -> str:
formatting/bibliographicformatting.py:def formatpublicationinfo(pubinfo: str) -> str:
formatting/bibliographicformatting.py:def avoidlonglines(string: str, maxlen: int, splitval: str, stringlist=list()) -> str:
formatting/bibliographicformatting.py:def formatauthorandworkinfo(authorname: str, workobject: dbOpus) -> str:
formatting/bracketformatting.py:def gtltsubstitutes(text: str) -> str:
formatting/bracketformatting.py:def brackethtmlifysearchfinds(listoflineobjects: list, searchobject: SearchObject, linehtmltemplate: str) -> list:
formatting/browserformatting.py:def insertparserids(lineobject: dbWorkLine, continuationdict: dict) -> str:
formatting/browserformatting.py:def bracketcheck(word: str) -> bool:
formatting/browserformatting.py:def addobservedtags(word: str, lastword: str, hyphenated: str) -> str:
formatting/jsformatting.py:def insertbrowserclickjs(tagname: str) -> str:
formatting/jsformatting.py:def insertlexicalbrowserjs() -> str:
formatting/jsformatting.py:def generatevectorjs() -> str:
formatting/jsformatting.py:def supplementalindexjs() -> str:
formatting/jsformatting.py:def dictionaryentryjs() -> str:
formatting/jsformatting.py:def morphologychartjs() -> str:
formatting/lexicaformatting.py:def formatdictionarysummary(wordentryobject) -> str:
formatting/lexicaformatting.py:def lexicaldbquickfixes(listofnames: list) -> Dict[str, str]:
formatting/lexicaformatting.py:def formatparsinginformation(possibilitieslist: List[MorphPossibilityObject]) -> str:
formatting/lexicaformatting.py:def getobservedwordprevalencedata(dictionaryword):
formatting/lexicaformatting.py:def formatprevalencedata(wordcountobject):
formatting/miscformatting.py:def timedecorator(function):
formatting/miscformatting.py:def validatepollid(searchid, maxchars=36) -> str:
formatting/miscformatting.py:def consolewarning(message: str, color='yellow', isbold=False, colorcoded=True, baremessage=False):
formatting/morphologytableformatting.py:def findmygreektenses(mood: str, voice: str) -> dict:
formatting/morphologytableformatting.py:def findmylatintenses(mood: str, voice: str) -> dict:
formatting/morphologytableformatting.py:def declinedtabletemplate(dialect='attic', duals=True, lang='greek', skipgenders=None) -> str:
formatting/morphologytableformatting.py:def verbtabletemplate(mood: str, voice: str, dialect='attic', duals=True, lang='greek') -> str:
formatting/morphologytableformatting.py:def filloutmorphtabletemplate(lookupdict: dict, wordcountdict: dict, template: str) -> str:
formatting/morphologytableformatting.py:def purgeemptyrows(templatetoclean: str) -> str:
formatting/searchformatting.py:def buildresultobjects(hitdict: dict, authordict: dict, workdict: dict, searchobject: SearchObject) -> ResultList:
formatting/searchformatting.py:def flagsearchterms(searchresultobject: SearchResult, skg: str, prx: str, searchobject: SearchObject) -> LineList:
formatting/searchformatting.py:def highlightsearchterm(lineobject: dbWorkLine, regexequivalent, spanname) -> str:
formatting/searchformatting.py:def htmlifysearchfinds(listofsearchresultobjects: ResultList, searchobject: SearchObject) -> str:
formatting/searchformatting.py:def nocontexthtmlifysearchfinds(listofsearchresultobjects: ResultList) -> str:
formatting/searchformatting.py:def unbalancedspancleaner(html: str) -> str:
formatting/sessionhtmlandjs.py:def sessionselectionsashtml(authordict: dict, workdict: dict) -> dict:
formatting/sessionhtmlandjs.py:def sessionselectionsjs(labeltupleslist: List[Tuple[str, int]]) -> str:
formatting/sessionhtmlandjs.py:def sessiontimeexclusionsinfo():
formatting/sessionhtmlandjs.py:def sessionselectionsinfo(authordict: dict, workdict: dict) -> dict:
formatting/sessionhtmlandjs.py:def selectionlinehtmlandjs(v: str, selectionorexclusion: str, thesession: session) -> dict:
formatting/vectorformatting.py:def formatlsimatches(listofmatches: List[dict]) -> str:
formatting/vectorformatting.py:def formatnnmatches(listofneighbors: List[tuple], vectorvalues: VectorValues):
formatting/vectorformatting.py:def formatnnsimilarity(termone: str, termtwo: str, similarityscore: float) -> str:
formatting/vectorformatting.py:def skformatmostimilar(similaritiesdict: dict) -> str:
formatting/vectorformatting.py:def locusformat(dblineobject: dbWorkLine) -> str:
formatting/vectorformatting.py:def vectorhtmlforfrontpage() -> str:
formatting/vectorformatting.py:def vectorhtmlforoptionsbar() -> str:
formatting/vectorformatting.py:def nearestneighborgenerateoutput(findshtml: str, mostsimilar: list, imagename: str, workssearched: int, searchobject: SearchObject) -> str:
formatting/vectorformatting.py:def lsiformatoutput(findshtml: str, workssearched: int, matches: list, searchobject: SearchObject) -> str:
formatting/vectorformatting.py:def ldatopicsgenerateoutput(ldavishtmlandjs: str, workssearched: int, settings: dict, searchobject: SearchObject):
formatting/wordformatting.py:def removegravity(accentedword: str) -> str:
formatting/wordformatting.py:def forceterminalacute(matchgroup: re.match) -> str:
formatting/wordformatting.py:def stripaccents(texttostrip: str, transtable=None) -> str:
formatting/wordformatting.py:def buildhipparchiatranstable() -> dict:
formatting/wordformatting.py:def gkattemptelision(hypenatedgreekheadword: str) -> str:
formatting/wordformatting.py:def latattemptelision(hypenatedlatinheadword: str) -> str:
formatting/wordformatting.py:def tidyupterm(word: str, punct=None) -> str:
formatting/wordformatting.py:def universalregexequivalent(searchterm: str) -> str:
formatting/wordformatting.py:def depunct(stringtoclean, allowedpunctuationsting=None):
formatting/wordformatting.py:def avoidsmallvariants(text: str) -> str:
formatting/wordformatting.py:def forcelunates(text: str) -> str:
formatting/wordformatting.py:def basiclemmacleanup(text: str) -> str:
formatting/wordformatting.py:def attemptsigmadifferentiation(text: str) -> str:
formatting/wordformatting.py:def abbreviatedsigmarestoration(text: str) -> str:
formatting/wordformatting.py:def wordlistintoregex(wordlist: list) -> str:
formatting/wordformatting.py:def upperorlowerregex(word: str) -> str:
formatting/wordformatting.py:def acuteorgrav(word: str) -> str:
formatting/wordformatting.py:def setdictionarylanguage(thisword) -> str:
hipparchiaobjects/searchfunctionobjects.py:def returnsearchfncobject(workerid, foundlineobjects, listofplacestosearch, searchobject, dbconnection, searchfunction):
listsandsession/checksession.py:def probeforsessionvariables():
listsandsession/checksession.py:def convertyesnototruefalse():
listsandsession/checksession.py:def corpusselectionsasavalue(thesession=None) -> int:
listsandsession/checksession.py:def corpusselectionsaspseudobinarystring(thesession=None) -> str:
listsandsession/checksession.py:def justlatin(thesession=None) -> bool:
listsandsession/checksession.py:def justtlg(thesession=None) -> bool:
listsandsession/checksession.py:def justinscriptions(thesession=None) -> bool:
listsandsession/checksession.py:def justpapyri(thesession=None) -> bool:
listsandsession/checksession.py:def justlit(thesession=None) -> bool:
listsandsession/checksession.py:def justdoc(thesession=None) -> bool:
listsandsession/checksession.py:def corpusisonandavailable(corpusname):
listsandsession/genericlistfunctions.py:def dictitemstartswith(originaldict: dict, element: str, muststartwith: str) -> dict:
listsandsession/genericlistfunctions.py:def findspecificdate(authorandworklist, authorobjectdict, workobjectdict, specificdate):
listsandsession/genericlistfunctions.py:def tidyuplist(untidylist: list) -> list:
listsandsession/genericlistfunctions.py:def dropdupes(checklist: list, matchlist: list) -> list:
listsandsession/genericlistfunctions.py:def polytonicsort(unsortedwords: list) -> list:
listsandsession/genericlistfunctions.py:def foundindict(searchdict: dict, element: str, mustbein: str, exactmatch=True) -> list:
listsandsession/searchlistmanagement.py:def compilesearchlist(listmapper: dict, s: dict) -> list:
listsandsession/searchlistmanagement.py:def sortsearchlist(searchlist: list, authorsdict: dict) -> list:
listsandsession/searchlistmanagement.py:def sortresultslist(hits: list, searchobject: SearchObject, authorsdict: dict, worksdict: dict) -> dict:
listsandsession/searchlistmanagement.py:def calculatewholeauthorsearches(searchlist: list, authordict: dict) -> list:
listsandsession/searchlistmanagement.py:def flagexclusions(searchlist: list, s=session) -> list:
listsandsession/searchlistmanagement.py:def prunebydate(searchlist: list, authorobjectdict: dict, workobjectdict: dict, s=session) -> list:
listsandsession/searchlistmanagement.py:def removespuria(searchlist: list, worksdict: dict) -> list:
listsandsession/searchlistmanagement.py:def buildhintlist(seeking: str, listofposiblities: list) -> list:
listsandsession/sessiondicts.py:def buildaugenresdict(authordict: dict) -> dict:
listsandsession/sessiondicts.py:def buildworkgenresdict(workdict: dict) -> dict:
listsandsession/sessiondicts.py:def buildauthorlocationdict(authordict: dict) -> dict:
listsandsession/sessiondicts.py:def buildworkprovenancedict(workdict: dict) -> dict:
listsandsession/sessiondicts.py:def buildkeyedlemmata(listofentries: dict) -> defaultdict:
listsandsession/sessionfunctions.py:def modifysessionvariable(parameter, value):
listsandsession/sessionfunctions.py:def validatevectorvalue(parameter, value):
listsandsession/sessionfunctions.py:def modifysessionselections(cookiedict, authorgenreslist, workgenreslist, authorlocationlist, workprovenancelist):
listsandsession/sessionfunctions.py:def parsejscookie(cookiestring: str) -> dict:
listsandsession/sessionfunctions.py:def rationalizeselections(newselectionuid, selectorexclude):
listsandsession/sessionfunctions.py:def reducetosessionselections(listmapper: dict, criterion: str) -> dict:
listsandsession/sessionfunctions.py:def returnactivedbs(thesession=None) -> List[str]:
listsandsession/sessionfunctions.py:def findactivebrackethighlighting(thesession=None) -> List[str]:
listsandsession/sessionfunctions.py:def selectionisactive(selected):
listsandsession/sessionfunctions.py:def returnactivelist(selectiondict: dict) -> List[str]:
listsandsession/validateconfig.py:def loadconfig(filepath) -> list:
listsandsession/validateconfig.py:def parseconfig(configlist) -> List[str]:
listsandsession/validateconfig.py:def compareconfigs(template, model) -> Dict[str, set]:
listsandsession/whereclauses.py:def configurewhereclausedata(searchlist: list, workdict: dict, searchobject: SearchObject) -> Dict[str, dict]:
listsandsession/whereclauses.py:def wholeworkbetweenclausecontents(listofworkobjects: list) -> List[Tuple[int, int]]:
listsandsession/whereclauses.py:def wholeworktemptablecontents(authorid: str, setoflinenumbers: set) -> Dict[str, str]:
listsandsession/whereclauses.py:def partialworkbetweenclausecontents(workobject: dbOpus, searchobject: SearchObject) -> Tuple[str, Dict[str, list]]:
routes/browseroute.py:def grabtextforbrowsing(method, author, work, location=None):
routes/cssroutes.py:def loadcssfile(cssrequest):
routes/frontpage.py:def frontpage():
routes/frontpage.py:def sendfavicon():
routes/frontpage.py:def appletouchticon():
routes/frontpage.py:def loadhelpdata():
routes/getterroutes.py:def getsessionvariables():
routes/getterroutes.py:def cookieintosession(cookienum):
routes/getterroutes.py:def findtheworksof(authoruid):
routes/getterroutes.py:def findworkstructure(author, work, passage=None):
routes/getterroutes.py:def getauthinfo(authorid):
routes/getterroutes.py:def getsearchlistcontents():
routes/getterroutes.py:def getgenrelistcontents():
routes/getterroutes.py:def fetchstoredimage(figurename):
routes/getterroutes.py:def returnvectorsettingsranges():
routes/hintroutes.py:def offerauthorhints():
routes/hintroutes.py:def augenrelist():
routes/hintroutes.py:def wkgenrelist():
routes/hintroutes.py:def offeraulocationhints():
routes/hintroutes.py:def offerprovenancehints():
routes/hintroutes.py:def offerlemmatahints():
routes/inforoutes.py:def databasecontents(dictionarytodisplay):
routes/inforoutes.py:def styesheetsamples():
routes/inforoutes.py:def showsessioncontents():
routes/inforoutes.py:def testroute():
routes/lexicalroutes.py:def dictsearch(searchterm):
routes/lexicalroutes.py:def findbyform(observedword):
routes/lexicalroutes.py:def reverselexiconsearch(searchterm):
routes/lexicalroutes.py:def dictionaryidsearch(language, entryid):
routes/lexicalroutes.py:def knownforms(lexicalid, language, xrefid, headword):
routes/resetroutes.py:def clearsession():
routes/resetroutes.py:def resetsemanticvectors():
routes/resetroutes.py:def resetvectorgraphs():
routes/searchroute.py:def executesearch(searchid, so=None):
routes/searchroute.py:def singlewordsearch(searchid, searchterm):
routes/searchroute.py:def headwordsearch(searchid, headform):
routes/searchroute.py:def vectorsearch(vectortype, searchid, headform):
routes/selectionroutes.py:def selectionmade():
routes/selectionroutes.py:def setsessionvariable(thevariable, thevalue):
routes/selectionroutes.py:def clearselections(category, index=-1):
routes/selectionroutes.py:def getcurrentselections():
routes/textandindexroutes.py:def buildindexto(searchid: str, author: str, work=None, passage=None):
routes/textandindexroutes.py:def textmaker(author: str, work=None, passage=None):
routes/websocketroutes.py:def checkforactivesearch(searchid):
searching/phrasesearching.py:def phrasesearch(wkid: str, searchobject: SearchObject, cursor) -> List[dbWorkLine]:
searching/phrasesearching.py:def subqueryphrasesearch(workerid, foundlineobjects: ListProxy, searchphrase: str, listofplacestosearch: ListProxy, searchobject: SearchObject, dbconnection) -> ListProxy:
searching/proximitysearching.py:def withinxlines(workdbname: str, searchobject: SearchObject, dbconnection) -> List[dbWorkLine]:
searching/proximitysearching.py:def withinxwords(workdbname: str, searchobject: SearchObject, dbconnection) -> List[dbWorkLine]:
searching/proximitysearching.py:def grableadingandlagging(hitline: dbWorkLine, searchobject: SearchObject, cursor) -> dict:
searching/searchdispatching.py:def searchdispatcher(searchobject: SearchObject) -> List[dbWorkLine]:
searching/searchdispatching.py:def workonsimplesearch(workerid: int, foundlineobjects: ListProxy, listofplacestosearch: ListProxy, searchobject: SearchObject, dbconnection) -> ListProxy:
searching/searchdispatching.py:def workonproximitysearch(workerid: int, foundlineobjects: ListProxy, listofplacestosearch: ListProxy, searchobject: SearchObject, dbconnection) -> ListProxy:
searching/searchdispatching.py:def workonphrasesearch(workerid: int, foundlineobjects: ListProxy, listofplacestosearch: ListProxy, searchobject: SearchObject, dbconnection) -> ListProxy:
searching/searchdispatching.py:def workonsimplelemmasearch(workerid: int, foundlineobjects: ListProxy, searchtuples: ListProxy, searchobject: SearchObject, dbconnection) -> ListProxy:
searching/searchfunctions.py:def cleaninitialquery(seeking: str) -> str:
searching/searchfunctions.py:def massagesearchtermsforwhitespace(query: str) -> str:
searching/searchfunctions.py:def atsignwhereclauses(uidwithatsign, operand, authors) -> List[tuple]:
searching/searchfunctions.py:def buildbetweenwhereextension(authortable: str, searchobject: SearchObject) -> str:
searching/searchfunctions.py:def lookoutsideoftheline(linenumber: int, numberofextrawords: int, workid: str, searchobject: SearchObject, cursor) -> str:
searching/searchfunctions.py:def findleastcommonterm(searchphrase: str, accentsneeded: bool) -> str:
searching/searchfunctions.py:def findleastcommontermcount(searchphrase: str, accentsneeded: bool) -> int:
searching/searchfunctions.py:def dblooknear(index: int, distanceinlines: int, secondterm: str, workid: str, usecolumn: str, cursor) -> bool:
searching/searchfunctions.py:def buildsearchobject(searchid: str, therequest: request, thesession: session) -> SearchObject:
searching/searchfunctions.py:def loadsearchqueue(iterable, workers):
searching/substringsearching.py:def substringsearch(seeking: str, authortable: str, searchobject: SearchObject, cursor, templimit=None) -> Generator:
semanticvectors/gensimlsi.py:def lsigenerateoutput(sentencestuples, workssearched, searchobject, lsispace):
semanticvectors/gensimlsi.py:def lsifindmatches(sentencestuples, searchobject, lsispace):
semanticvectors/gensimlsi.py:def lsibuildspace(morphdict, sentences):
semanticvectors/gensimnearestneighbors.py:def generatenearestneighbordata(sentencetuples, workssearched, searchobject, vectorspace):
semanticvectors/gensimnearestneighbors.py:def buildnnvectorspace(sentencetuples, searchobject):
semanticvectors/gensimnearestneighbors.py:def findapproximatenearestneighbors(query, mymodel, vectorvalues: VectorValues):
semanticvectors/gensimnearestneighbors.py:def findword2vecsimilarities(termone, termtwo, mymodel):
semanticvectors/gensimnearestneighbors.py:def buildgensimmodel(searchobject, morphdict, sentences):
semanticvectors/gensimvectors.py:def executegensimsearch(searchobject):
semanticvectors/preparetextforvectorization.py:def vectorprepdispatcher(searchobject):
semanticvectors/preparetextforvectorization.py:def breaktextsintosentences(foundsentences, searchlist, searchobject, dbconnection):
semanticvectors/rudimentaryvectormath.py:def finddotproduct(listofavalues, listofbvalues):
semanticvectors/rudimentaryvectormath.py:def findvectorlength(listofvalues):
semanticvectors/rudimentaryvectormath.py:def findcosinedist(avalues, lemmavalues, lemmavaluelength):
semanticvectors/rudimentaryvectormath.py:def caclulatecosinevalues(focusword, vectorspace, headwords):
semanticvectors/rudimentaryvectormath.py:def buildrudimentaryvectorspace(allheadwords, morphdict, sentences, subtractterm=None):
semanticvectors/rudimentaryvectormath.py:def vectorcosinedispatching(focusword, vectorspace, headwords):
semanticvectors/rudimentaryvectormath.py:def vectorcosineworker(headwords, workpiledict, resultdict):
semanticvectors/scikitlearntopics.py:def sklearnselectedworks(searchobject):
semanticvectors/scikitlearntopics.py:def ldatopicgraphing(sentencetuples, workssearched, searchobject, headwordstops=True):
semanticvectors/vectorgraphing.py:def graphbliteraldistancematches(searchterm, mostsimilartuples, searchobject):
semanticvectors/vectorgraphing.py:def graphnnmatches(searchterm, mostsimilartuples, vectorspace, searchobject):
semanticvectors/vectorgraphing.py:def graphmatches(graphtitle, searchterm, searchobject, mostsimilartuples, terms, relevantconnections, vtype):
semanticvectors/vectorgraphing.py:def matplotgraphmatches(graphtitle, searchterm, searchobject, mostsimilartuples, terms, relevantconnections, vtype):
semanticvectors/vectorgraphing.py:def storevectorgraph(figureasbytes):
semanticvectors/vectorgraphing.py:def fetchvectorgraph(imagename):
semanticvectors/vectorgraphing.py:def givetitletograph(topic, searchterm, searchobject):
semanticvectors/vectorgraphing.py:def generatethefineprint(vtype: str, vectorvalues: VectorValues) -> str:
semanticvectors/vectorhelpers.py:def cleantext(texttostrip):
semanticvectors/vectorhelpers.py:def replaceabbreviations(foundstring, searchdict):
semanticvectors/vectorhelpers.py:def recursivesplit(tosplit, listofsplitlerms):
semanticvectors/vectorhelpers.py:def findsentences(authortable, searchobject, cursor):
semanticvectors/vectorhelpers.py:def parsevectorsentences(searchobject, lineobjects):
semanticvectors/vectorhelpers.py:def findwordvectorset(listofwordclusters: list) -> set:
semanticvectors/vectorhelpers.py:def convertmophdicttodict(morphdict: dict) -> dict:
semanticvectors/vectorhelpers.py:def buildlemmatizesearchphrase(phrase: str) -> str:
semanticvectors/vectorhelpers.py:def bruteforcefinddblinefromsentence(thissentence, modifiedsearchobject):
semanticvectors/vectorhelpers.py:def finddblinesfromsentences(thissentence, sentencestuples, cursor):
semanticvectors/vectorhelpers.py:def convertlineuidstolineobject(listoflines, cursor):
semanticvectors/vectorhelpers.py:def convertsingleuidtodblineobject(lineuid, cursor):
semanticvectors/vectorhelpers.py:def buildflatbagsofwords(morphdict, sentences):
semanticvectors/vectorhelpers.py:def buildbagsofwordswithalternates(morphdict, sentences):
semanticvectors/vectorhelpers.py:def mostcommoninflectedforms(cheat=True) -> set:
semanticvectors/vectorhelpers.py:def uselessforeignwords() -> set:
semanticvectors/vectorhelpers.py:def mostcommonheadwords(cheat=True) -> set:
semanticvectors/vectorhelpers.py:def mostcommonwordsviaheadwords() -> set:
semanticvectors/vectorhelpers.py:def removestopwords(sentencestring, stopwords):
semanticvectors/vectorhelpers.py:def relativehomonymnweight(worda, wordb, morphdict) -> float:
semanticvectors/vectorhelpers.py:def readgitdata():
semanticvectors/vectorpseudoroutes.py:def findabsolutevectorsbysentence(searchobject):
semanticvectors/vectorpseudoroutes.py:def findabsolutevectorsfromhits(searchobject, hitdict, workssearched):
semanticvectors/vectorpseudoroutes.py:def generateabsolutevectorsoutput(listsofwords: list, workssearched: list, searchobject, vtype: str):
semanticvectors/vectorpseudoroutes.py:def emptyvectoroutput(searchobject, reasons=list()):
textsandindices/indexmaker.py:def buildindextowork(cdict: dict, activepoll, headwords: bool, cursor) -> List[tuple]:
textsandindices/indexmaker.py:def generatesortedoutputbyword(completeindexdict: dict, onework: bool, alphabetical: bool) -> List[tuple]:
textsandindices/indexmaker.py:def generatesortedoutputbyheadword(completeindexdict: dict, onework: bool, alphabetical: bool, activepoll) -> List[tuple]:
textsandindices/indexmaker.py:def findindexbaseforms(completeindexdict, morphobjects, activepoll) -> dict:
textsandindices/indexmaker.py:def generateheadwordindexdict(augmentedindexdict) -> dict:
textsandindices/indexmaker.py:def htmlifysimpleindex(completeindexdict, onework) -> List[tuple]:
textsandindices/indexmaker.py:def linesintoindex(lineobjects: List[dbWorkLine], activepoll) -> dict:
textsandindices/indexmaker.py:def pooledindexmaker(lineobjects: List[dbWorkLine]) -> dict:
textsandindices/textandindiceshelperfunctions.py:def textsegmentfindstartandstop(authorobject, workobject, passageaslist, cursor) -> dict:
textsandindices/textandindiceshelperfunctions.py:def wordindextohtmltable(indexingoutput: List[tuple], useheadwords: bool) -> str:
textsandindices/textandindiceshelperfunctions.py:def dictmerger(masterdict: dict, targetdict: dict):
textsandindices/textandindiceshelperfunctions.py:def setcontinuationvalue(thisline: dbWorkLine, previousline: dbWorkLine, previouseditorialcontinuationvalue: bool, brktype: str, openfinder=None, closefinder=None):
textsandindices/textandindiceshelperfunctions.py:def getrequiredmorphobjects(setofterms: set, furtherdeabbreviate=False):
textsandindices/textandindiceshelperfunctions.py:def mpmorphology(terms: list, furtherdeabbreviate: bool, morphobjects, dbconnection: ConnectionObject):
textsandindices/textandindiceshelperfunctions.py:def paragraphformatting(listoflines: List[dbWorkLine]) -> List[dbWorkLine]:
textsandindices/textbuilder.py:def buildtext(work: str, firstline: int, lastline: int, linesevery: int, cursor) -> str:
textsandindices/textbuilder.py:def determinelinetemplate(shownotes=True) -> str:
threading/mpthreadcount.py:def setthreadcount(startup=False) -> int:
threading/vectordbautopilot.py:def startvectorizing():
threading/vectordbautopilot.py:def determinevectorworkpile(tempcap=False) -> List[tuple]:
threading/vectordbautopilot.py:def buildfakesearchobject(qtype='nearestneighborsquery') -> SearchObject:
threading/websocketthread.py:def startwspolling(theport=hipparchia.config['PROGRESSPOLLDEFAULTPORT']):